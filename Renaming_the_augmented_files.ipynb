{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import cm\n",
    "import librosa\n",
    "import csv\n",
    "import os\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Absolute path of a file\n",
    "old_name = r\"D:\\balanced_1s_not_aug\\1s_balancedChunks\\train\\ff\\1603942345102x_0.wav\"\n",
    "new_name = r\"D:\\balanced_1s_not_aug\\1s_balancedChunks\\train\\ff\\1603942345102_0.wav\"\n",
    "\n",
    "# Renaming the file\n",
    "os.rename(old_name, new_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = 'D:/balanced_1s_not_aug/1s_balancedChunks/test/ss/'\n",
    "#root = 'D:/COVID_COUGH_SOUNDS/1second_chunks_458/NON_AUGMENTED_1_SEC_CHUNKS_NO_OVERLAP/train'\n",
    "renam_filenames= []\n",
    "for path, subdirs, files in os.walk(root):\n",
    "    for name in files:\n",
    "        #print(os.path.join(path, name))\n",
    "        renam_filenames.append(os.path.join(path, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(renam_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_names =  []\n",
    "for i in range(len(renam_filenames)):\n",
    "    a = renam_filenames[i].split('/')[-1]\n",
    "    s = a[:13] + \"b\" + a[13:]\n",
    "    new_names.append(s)\n",
    "    #print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'D:/balanced_1s_not_aug/1s_balancedChunks/test/ss/'\n",
    "new_filenames= []\n",
    "\n",
    "for name in new_names:\n",
    "        #print(os.path.join(path, name))\n",
    "        new_filenames.append(os.path.join(path, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(renam_filenames)):\n",
    "    os.rename(renam_filenames[i], new_filenames[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1603942345102_1.wav 1603942345102b_1.wav\n"
     ]
    }
   ],
   "source": [
    "a = renam_filenames[1].split('/')[-1]\n",
    "s = a[:13] + \"b\" + a[13:]\n",
    "print(a, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = a[:13] + \"b\" + a[13:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_names =  []\n",
    "for i in range(len(renam_filenames)):\n",
    "    a = renam_filenames[i].split('/')[-1]\n",
    "    s = a[:13] + \"b\" + a[13:]\n",
    "    new_names.append(s)\n",
    "    #print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = 'D:/balanced_1s_not_aug/1s_balancedChunks/train/'\n",
    "#root = 'D:/COVID_COUGH_SOUNDS/1second_chunks_458/NON_AUGMENTED_1_SEC_CHUNKS_NO_OVERLAP/train'\n",
    "train_filenames= []\n",
    "for path, subdirs, files in os.walk(root):\n",
    "    for name in files:\n",
    "        #print(os.path.join(path, name))\n",
    "        train_filenames.append(os.path.join(path, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA_DIR='D:/COVID_COUGH_SOUNDS/DATASET_FINAL/WEBAPP+COUGHVID_CHUNKS_50_OVERLAP/allergies/'\n",
    "#filenames =glob(DATA_DIR + '/*.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_t = 'D:/balanced_1s_not_aug/1s_balancedChunks/test/'\n",
    "#root = 'D:/COVID_COUGH_SOUNDS/1second_chunks_458/NON_AUGMENTED_1_SEC_CHUNKS_NO_OVERLAP/train'\n",
    "test_filenames= []\n",
    "for path, subdirs, files in os.walk(root_t):\n",
    "    for name in files:\n",
    "        #print(os.path.join(path, name))\n",
    "        test_filenames.append(os.path.join(path, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:/COVID_COUGH_SOUNDS/1second_chunks_458/balanced_1s_not_aug/1s_balancedChunks/test/pneumonia\\\\1595212847994b_0.wav'"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_filenames[-104]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio_file(file_path):\n",
    "    input_length = 16000\n",
    "    data = librosa.core.load(file_path)[0] #, sr=16000\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_files():\n",
    "    # we will be leaving some files out, on purpose. Do not change this function!\n",
    "    return [os.path.join(DATA_DIR, x) for x in sorted(os.listdir(DATA_DIR)) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sound_id_from_file_path(file_path):\n",
    "    a = file_path.split('\\\\')[-2:]\n",
    "    #b= file_path.split('/')[-1:]\n",
    "    #c= file_path.split('\\\\')[-1:]\n",
    "    return a\n",
    "    #return a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/COVID_COUGH_SOUNDS/1second_chunks_458/balanced_1s_not_aug/1s_balancedChunks/test/allergies\\1591363379163_1.wav\n",
      "D:/COVID_COUGH_SOUNDS/1second_chunks_458/balanced_1s_not_aug/1s_balancedChunks/test/allergies\n",
      "1591363379163_1.wav\n",
      "allergies\n"
     ]
    }
   ],
   "source": [
    "print(test_filenames[1])\n",
    "correlation, key = get_sound_id_from_file_path(test_filenames[1])\n",
    "correlation, key = get_sound_id_from_file_path(test_filenames[1])\n",
    "d = correlation.split('/')[-1]\n",
    "print(correlation)\n",
    "print(key)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2010"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:/COVID_COUGH_SOUNDS/1second_chunks_458/balanced_1s_not_aug/1s_balancedChunks/test/allergies'"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractWavFeatures(soundFilesFolder, csvFileName, xfilenames):\n",
    "    print(\"The features of the files in the folder \"+soundFilesFolder+\" will be saved to \"+csvFileName)\n",
    "    header = 'key correlation chroma_stft rmse spectral_centroid spectral_bandwidth rolloff zero_crossing_rate'\n",
    "    for i in range(1, 21):\n",
    "        header += f' mfcc{i}'\n",
    "    #header += ' label'\n",
    "    header = header.split()\n",
    "    print('CSV Header: ', header)\n",
    "    file = open(csvFileName, 'w', newline='')\n",
    "    #with file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(header)\n",
    "    test_filenames= []\n",
    "    for path, subdirs, files in os.walk(soundFilesFolder):\n",
    "        for name in files:\n",
    "        #print(os.path.join(path, name))\n",
    "            test_filenames.append(os.path.join(path, name))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in xfilenames:\n",
    "        dirname, key  = get_sound_id_from_file_path(i)\n",
    "        correlation = dirname.split('/')[-1]\n",
    "        y, sr = librosa.load(i, mono=True, duration=30)\n",
    "        \n",
    "        # remove leading and trailing silence\n",
    "        \n",
    "        y, index = librosa.effects.trim(y)\n",
    "        \n",
    "        chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "        rmse = librosa.feature.rms(y=y)\n",
    "        spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "        spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "        rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "        zcr = librosa.feature.zero_crossing_rate(y)\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
    "        \n",
    "        to_append = f' {key} {correlation} {np.mean(chroma_stft)} {np.mean(rmse)} {np.mean(spec_cent)} {np.mean(spec_bw)} {np.mean(rolloff)} {np.mean(zcr)}'\n",
    "        for e in mfcc:\n",
    "            to_append += f' {np.mean(e)}'\n",
    "        writer.writerow(to_append.split())\n",
    "    file.close()\n",
    "    print(\"End of extractWavFeatures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "CREATE_CSV_FILES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAIN_CSV_FILE = \"D:/COVID_COUGH_SOUNDS/1second_chunks_458/NON_AUGMENTED_1_SEC_CHUNKS_NO_OVERLAP/MFCC_train.csv\"\n",
    "#TEST_CSV_FILE = \"D:/COVID_COUGH_SOUNDS/1second_chunks_458/NON_AUGMENTED_1_SEC_CHUNKS_NO_OVERLAP/MFCC_test.csv\"\n",
    "#MORE_TRAIN_CSV_FILE = \"C:/Users/Asus/Documents/COVID19/MFCC/test/more_train.csv\"\n",
    "#MORE_TEST_CSV_FILE = \"C:/Users/Asus/Documents/COVID19/MFCC/test/more_test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_CSV_FILE ='D:/balanced_1s_not_aug/1s_balancedChunks/1sec_chunk_train_mfcc.csv'\n",
    "TEST_CSV_FILE ='D:/balanced_1s_not_aug/1s_balancedChunks/1sec_chunk_test_mfcc.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import cm\n",
    "import librosa\n",
    "import csv\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "if (CREATE_CSV_FILES == True):\n",
    "    extractWavFeatures(\"D:/balanced_1s_not_aug/1s_balancedChunks/train/\", TRAIN_CSV_FILE, train_filenames)\n",
    "    extractWavFeatures(\"D:/balanced_1s_not_aug/1s_balancedChunks/test/\", TEST_CSV_FILE, test_filenames)\n",
    "    #extractWavFeatures(\"C:/Users/Asus/Documents/COVID19/MFCC/moreSpeakersTrain\", MORE_TRAIN_CSV_FILE)\n",
    "    #extractWavFeatures(\"C:/Users/Asus/Documents/COVID19/MFCC/moreSpeakersTest\", MORE_TEST_CSV_FILE)\n",
    "    print(\"CSV files are created\")\n",
    "else:\n",
    "    print(\"CSV files creation is skipped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv(TRAIN_CSV_FILE, sep=',')\n",
    "test = pd.read_csv(TEST_CSV_FILE, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAIN_CSV_FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#train = pd.read_csv(TRAIN_CSV_FILE)\n",
    "test = pd.read_csv(TEST_CSV_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[['filename','chunk']]= train['key'].str.split('_', 1, expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train['chunk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train['key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['filename'] = pd.factorize(train['filename'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[['filename','chunk']]= test['key'].str.split('_', 1, expand=True)\n",
    "del test['chunk']\n",
    "del test['key']\n",
    "test['filename'] = pd.factorize(test['filename'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "allergies    402\n",
       "asthma       402\n",
       "covid        402\n",
       "other        402\n",
       "pneumonia    402\n",
       "Name: correlation, dtype: int64"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['correlation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "allergies    104\n",
       "asthma       104\n",
       "covid        104\n",
       "other        104\n",
       "pneumonia    104\n",
       "Name: correlation, dtype: int64"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['correlation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test['correlation'] = pd.factorize(test['correlation'])[0]\n",
    "#train['correlation'] = pd.factorize(train['correlation'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    104\n",
      "1    104\n",
      "2    104\n",
      "3    104\n",
      "4    104\n",
      "Name: correlation, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(test['correlation'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    402\n",
      "1    402\n",
      "2    402\n",
      "3    402\n",
      "4    402\n",
      "Name: correlation, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train['correlation'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    402\n",
      "1    402\n",
      "2    402\n",
      "3    402\n",
      "4    402\n",
      "Name: correlation, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train['correlation'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MACHINE LEARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = [0, 1]\n",
    "train_2 = train[train.correlation.isin(corr)]\n",
    "test_2 = test[test.correlation.isin(corr)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_2.loc[:, train_2.columns!='correlation']\n",
    "X_test = test_2.loc[:, test_2.columns!='correlation']\n",
    "y_train  = train_2['correlation']\n",
    "y_test = test_2['correlation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train['filename']\n",
    "del X_test['filename']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "ms = MinMaxScaler()\n",
    "\n",
    "X_train= ms.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(X_train)\n",
    "\n",
    "X_test= ms.fit_transform(X_test)\n",
    "X_test = pd.DataFrame(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM accuracy:  0.5336538461538461\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[56, 48],\n",
       "       [49, 55]], dtype=int64)"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "model =SVC()\n",
    "model.fit (X_train, y_train)\n",
    "svm_pred = model.predict(X_test)\n",
    "print ('SVM accuracy: ', accuracy_score (y_test, svm_pred))\n",
    "confusion_matrix(y_test,svm_pred )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>correlation</th>\n",
       "      <th>SVM prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>208 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     filename  correlation  SVM prediction\n",
       "0           0            0               1\n",
       "1           0            0               1\n",
       "2           0            0               1\n",
       "3           0            0               1\n",
       "4           0            0               1\n",
       "..        ...          ...             ...\n",
       "203        24            1               0\n",
       "204        24            1               0\n",
       "205        24            1               0\n",
       "206        24            1               0\n",
       "207        24            1               0\n",
       "\n",
       "[208 rows x 3 columns]"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_test_values = test_2.loc[:, ['filename','correlation']]\n",
    "keys = true_test_values.filename.unique()\n",
    "true_test_values['SVM prediction'] = svm_pred\n",
    "#true_test_values['SVM prediction'] = y_pred\n",
    "true_test_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mode\n",
    "\n",
    "Mode = []\n",
    "Mode2 = []\n",
    "\n",
    "for i in keys:\n",
    "    m = true_test_values[true_test_values['filename']==i]['correlation'].values\n",
    "    m2 = true_test_values[true_test_values['filename']==i]['SVM prediction'].values\n",
    "    \n",
    "    #print(m)\n",
    "    \n",
    "    s = mode(m)[0]\n",
    "    s2 = mode(m2)[0]\n",
    "    \n",
    "    Mode.append(s[0])\n",
    "    Mode2.append(s2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_list = []\n",
    "for i in range(len(Mode)):\n",
    "    for j in range(len(Mode2)):\n",
    "        if (i==j):\n",
    "            if (Mode[i]==Mode2[j]):\n",
    "                new_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of chunks after voting: 0.4\n"
     ]
    }
   ],
   "source": [
    "#17/83\n",
    "score = len(new_list)/len(Mode2)\n",
    "print('Accuracy score of chunks after voting:',score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP accuracy:  0.5865384615384616\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[84, 20],\n",
       "       [14, 90]], dtype=int64)"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "clf = MLPClassifier(random_state=1, max_iter=2000).fit(X_train, y_train)\n",
    "#clf.predict_proba(X_test)\n",
    "\n",
    "clf.predict(X_test)\n",
    "\n",
    "print('MLP accuracy: ',clf.score(X_test, y_test))\n",
    "confusion_matrix(y_test,y_pred )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest Accuracy:  0.5625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[62, 42],\n",
       "       [49, 55]], dtype=int64)"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators = 100)\n",
    "rf.fit(X_train, y_train)\n",
    "predict_cough_type = rf.predict(X_test)\n",
    "print ('Random forest Accuracy: ', accuracy_score (y_test, predict_cough_type))\n",
    "#predict_cough_type = rf.predict(X_test)\n",
    "#print ('Accuracy: ', accuracy_score (y_test, predict_cough_type))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, predict_cough_type)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
