{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab368d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorboard\n",
    "import torchvision\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "2fec77f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "            [#transforms.ToPILImage(),\n",
    "            transforms.Resize([224, 224]),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "            transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "63854674",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "test_classes = []\n",
    "test_x = next(os.walk('D:/COVID_COUGH_SOUNDS/1second_chunks_458/stft_images_1sec_no_overlap/test/allergies/'))[2]\n",
    "test_y = next(os.walk('D:/COVID_COUGH_SOUNDS/1second_chunks_458/stft_images_1sec_no_overlap/test/covid/'))[2]\n",
    "for i in range(len(test_x)):\n",
    "    test_classes.append(0)\n",
    "for i in range(len(test_y)):\n",
    "    test_classes.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "fef186c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_path = []\n",
    "\n",
    "root_dir = 'D:/COVID_COUGH_SOUNDS/1second_chunks_458/stft_images_1sec_no_overlap/test/'\n",
    "classname1 = 'allergies/'\n",
    "classname2 = 'covid/'\n",
    "\n",
    "for index in range(len(test_x)):\n",
    "    test_image_path.append(os.path.join(root_dir, classname1, test_x[index]))\n",
    "for index in range(len(test_y)):\n",
    "    test_image_path.append(os.path.join(root_dir, classname2, test_y[index]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a1542732",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_classes = []\n",
    "train_x = next(os.walk('D:/COVID_COUGH_SOUNDS/1second_chunks_458/stft_images_1sec_no_overlap/train/allergies/'))[2]\n",
    "train_y = next(os.walk('D:/COVID_COUGH_SOUNDS/1second_chunks_458/stft_images_1sec_no_overlap/train/covid/'))[2]\n",
    "for i in range(len(train_x)):\n",
    "    train_classes.append(0)\n",
    "for i in range(len(train_y)):\n",
    "    train_classes.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "db0da4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_path = []\n",
    "\n",
    "root_dir = 'D:/COVID_COUGH_SOUNDS/1second_chunks_458/stft_images_1sec_no_overlap/train/'\n",
    "classname1 = 'allergies/'\n",
    "classname2 = 'covid/'\n",
    "\n",
    "for index in range(len(train_x)):\n",
    "    train_image_path.append(os.path.join(root_dir, classname1, train_x[index]))\n",
    "for index in range(len(train_y)):\n",
    "    train_image_path.append(os.path.join(root_dir, classname2, train_y[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aabe5027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:/COVID_COUGH_SOUNDS/1second_chunks_458/stft_images_1sec_no_overlap/train/allergies/1601354644605_0.png',\n",
       " 'D:/COVID_COUGH_SOUNDS/1second_chunks_458/stft_images_1sec_no_overlap/train/allergies/1601354644605_1.png',\n",
       " 'D:/COVID_COUGH_SOUNDS/1second_chunks_458/stft_images_1sec_no_overlap/train/allergies/1601354644605_2.png',\n",
       " 'D:/COVID_COUGH_SOUNDS/1second_chunks_458/stft_images_1sec_no_overlap/train/allergies/1601354644605_3.png']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_image_path[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d6547423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2],\n",
       "       [ 3,  4],\n",
       "       [ 5,  6],\n",
       "       [ 7,  8],\n",
       "       [ 9, 10],\n",
       "       [11, 12]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = np.array([[1, 2, 3, 4],\n",
    "         [5, 6, 7, 8],\n",
    "         [9, 10, 11, 12]])\n",
    "z.reshape(-1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ed1ab6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "  \n",
    "# open method used to open different extension image file\n",
    "im = Image.open(r'D:\\COVID_COUGH_SOUNDS\\1second_chunks_458\\stft_images_1sec_no_overlap\\test\\allergies\\1591363379163_0.png').convert('RGB')\n",
    "  \n",
    "# This method will show image in any image viewer \n",
    "im.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "0fa868bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from skimage import io\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "class LandmarkDataset(Dataset):\n",
    "    def __init__(self, image_paths, classes, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.transform = transform\n",
    "        self.classes = classes\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "            \n",
    "        image_filepath = self.image_paths[idx]\n",
    "        image = io.imread(image_filepath )  \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        \n",
    "        label = self.classes[idx]\n",
    "        #label = np.array([label])\n",
    "        label = torch.tensor(label, dtype  = torch.long)\n",
    "        #sample = {'image': image, 'label': label}\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "       \n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "3088f4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "            [#transforms.ToPILImage(),\n",
    "            transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "bc4e5b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = LandmarkDataset(train_image_path,train_classes, transform)\n",
    "test_dataset = LandmarkDataset(test_image_path, test_classes, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "20b2d399",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = LandmarkDataset(train_image_path,train_classes)\n",
    "test_dataset = LandmarkDataset(test_image_path, test_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "9a05c97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=1, shuffle=True\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=1, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "5bc9beaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0])\n",
      "tensor([0])\n",
      "tensor([1])\n",
      "tensor([1])\n",
      "tensor([0])\n",
      "tensor([1])\n",
      "tensor([0])\n",
      "tensor([1])\n",
      "tensor([1])\n",
      "tensor([1])\n",
      "tensor([1])\n",
      "tensor([0])\n",
      "tensor([1])\n",
      "tensor([1])\n",
      "tensor([1])\n",
      "tensor([1])\n",
      "tensor([0])\n",
      "tensor([1])\n",
      "tensor([0])\n",
      "tensor([1])\n",
      "tensor([1])\n",
      "tensor([1])\n",
      "tensor([1])\n",
      "tensor([1])\n",
      "tensor([1])\n",
      "tensor([1])\n",
      "tensor([0])\n",
      "tensor([0])\n",
      "tensor([0])\n",
      "tensor([1])\n",
      "tensor([1])\n",
      "tensor([0])\n",
      "tensor([1])\n",
      "tensor([1])\n",
      "tensor([0])\n",
      "tensor([1])\n",
      "tensor([1])\n",
      "tensor([0])\n",
      "tensor([0])\n",
      "tensor([0])\n",
      "tensor([1])\n",
      "tensor([1])\n",
      "tensor([1])\n",
      "tensor([1])\n",
      "tensor([0])\n",
      "tensor([1])\n",
      "tensor([0])\n",
      "tensor([1])\n",
      "tensor([1])\n",
      "tensor([0])\n",
      "tensor([1])\n",
      "tensor([1])\n",
      "tensor([0])\n",
      "tensor([1])\n",
      "tensor([1])\n",
      "tensor([1])\n",
      "tensor([1])\n",
      "tensor([0])\n",
      "tensor([1])\n",
      "tensor([1])\n",
      "tensor([1])\n",
      "tensor([0])\n",
      "tensor([0])\n",
      "tensor([1])\n",
      "tensor([1])\n",
      "tensor([1])\n",
      "tensor([1])\n",
      "tensor([1])\n",
      "tensor([1])\n",
      "tensor([0])\n",
      "tensor([1])\n",
      "tensor([1])\n",
      "tensor([0])\n",
      "tensor([0])\n",
      "tensor([1])\n",
      "tensor([0])\n",
      "tensor([1])\n",
      "tensor([1])\n",
      "tensor([1])\n",
      "tensor([0])\n",
      "tensor([0])\n",
      "tensor([0])\n",
      "tensor([1])\n",
      "tensor([1])\n",
      "tensor([1])\n",
      "tensor([1])\n",
      "tensor([0])\n",
      "tensor([1])\n",
      "tensor([0])\n",
      "tensor([1])\n",
      "tensor([0])\n",
      "tensor([1])\n",
      "tensor([0])\n",
      "tensor([1])\n",
      "tensor([1])\n",
      "tensor([1])\n",
      "tensor([1])\n",
      "tensor([1])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20764/632454434.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torchgpu\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torchgpu\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    559\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torchgpu\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torchgpu\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20764/931635155.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mimage_filepath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_paths\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_filepath\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torchgpu\\lib\\site-packages\\skimage\\io\\_io.py\u001b[0m in \u001b[0;36mimread\u001b[1;34m(fname, as_gray, plugin, **plugin_args)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mfile_or_url_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_plugin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'imread'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplugin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplugin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mplugin_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ndim'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torchgpu\\lib\\site-packages\\skimage\\io\\manage_plugins.py\u001b[0m in \u001b[0;36mcall_plugin\u001b[1;34m(kind, *args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m                                (plugin, kind))\n\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 207\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torchgpu\\lib\\site-packages\\skimage\\io\\_plugins\\imageio_plugin.py\u001b[0m in \u001b[0;36mimread\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimageio_imread\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimageio_imread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\torchgpu\\lib\\site-packages\\imageio\\core\\functions.py\u001b[0m in \u001b[0;36mimread\u001b[1;34m(uri, format, **kwargs)\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[0mreader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"i\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 267\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    268\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torchgpu\\lib\\site-packages\\imageio\\core\\format.py\u001b[0m in \u001b[0;36mget_data\u001b[1;34m(self, index, **kwargs)\u001b[0m\n\u001b[0;32m    344\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_BaseReaderWriter_last_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 346\u001b[1;33m                 \u001b[0mim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    347\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torchgpu\\lib\\site-packages\\imageio\\plugins\\pillow.py\u001b[0m in \u001b[0;36m_get_data\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    300\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_get_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 301\u001b[1;33m             \u001b[0mim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPillowFormat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mReader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    302\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ignoregamma\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m                 \u001b[1;31m# The gamma value in the file represents the gamma factor for the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torchgpu\\lib\\site-packages\\imageio\\plugins\\pillow.py\u001b[0m in \u001b[0;36m_get_data\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    178\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_im\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpalette\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrawmode_saved\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_im\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpalette\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrawmode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_im\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetdata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m             \u001b[0mim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpil_get_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_im\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_im\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torchgpu\\lib\\site-packages\\imageio\\plugins\\pillow.py\u001b[0m in \u001b[0;36mpil_get_frame\u001b[1;34m(im, is_gray, as_gray, mode, dtype)\u001b[0m\n\u001b[0;32m    788\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"PNG\"\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"I\"\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m             \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"uint16\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 790\u001b[1;33m         \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    791\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    792\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torchgpu\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[0m__array_interface__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 703\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mArrayData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    704\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    705\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getstate__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for data in test_loader:\n",
    "    inputs, labels = data[0], data[1]\n",
    "    print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "f10b3758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.LandmarkDataset at 0x1a1771f25b0>"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "6a173a00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x1a1771f2e50>"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "44b997ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1224"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "1658b88f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e401113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 class classification\n",
    "#train_dataset = datasets.ImageFolder(root='D:/COVID_COUGH_SOUNDS/1second_chunks_458/stft_images_1sec_no_overlap/train', transform=transform)\n",
    "#test_dataset  = datasets.ImageFolder(root='D:/COVID_COUGH_SOUNDS/1second_chunks_458/stft_images_1sec_no_overlap/test',  transform=transform)\n",
    "#valid_dataset  = datasets.ImageFolder(root='D:/split_data_breast/val',  \n",
    "                                     #transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4af2f49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from torch.utils.data import DataLoader\n",
    "\n",
    "#train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "#test_dataloader = DataLoader(test_dataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "949e4b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_dataset.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "379e344e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.LandmarkDataset at 0x2e31b646fa0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "badbb008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.LandmarkDataset at 0x2e31b646a90>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "50aa9283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1224"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b14af8b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d6df739f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from torch.utils.data import DataLoader\n",
    "\n",
    "#train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "#test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "#valid_dataloader = DataLoader(valid_dataset, batch_size=96, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c963b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "#resnet18 = models.resnet18(pretrained=True)\n",
    "alexnet = models.alexnet(pretrained=True)\n",
    "vgg16 = models.vgg16(pretrained=True)\n",
    "#squeezenet = models.squeezenet1_0(pretrained=True)\n",
    "densenet = models.densenet161(pretrained=True)\n",
    "#inception = models.inception_v3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "ccce86aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for param in densenet.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "densenet.classifier = nn.Linear(2208,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "70936701",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "184f7e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "c7484019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1224"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "fc3626d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = next(iter(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "ad8a68bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[255, 255, 255, ..., 255, 255, 255],\n",
       "         [255, 255, 255, ..., 255, 255, 255],\n",
       "         [255, 255, 255, ..., 255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255, ..., 255, 255, 255],\n",
       "         [255, 255, 255, ..., 255, 255, 255],\n",
       "         [255, 255, 255, ..., 255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255, ..., 255, 255, 255],\n",
       "         [255, 255, 255, ..., 255, 255, 255],\n",
       "         [255, 255, 255, ..., 255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255, ..., 255, 255, 255],\n",
       "         [255, 255, 255, ..., 255, 255, 255],\n",
       "         [255, 255, 255, ..., 255, 255, 255]],\n",
       " \n",
       "        [[255, 255, 255, ..., 255, 255, 255],\n",
       "         [255, 255, 255, ..., 255, 255, 255],\n",
       "         [255, 255, 255, ..., 255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255, ..., 255, 255, 255],\n",
       "         [255, 255, 255, ..., 255, 255, 255],\n",
       "         [255, 255, 255, ..., 255, 255, 255]]], dtype=uint8),\n",
       " tensor([0]))"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "5d87c543",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i, data in enumerate(train_loader, 0):\n",
    "            \n",
    "            #inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            #print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "b09b97d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_and_test(model, learning_rate):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "    model.to(device)\n",
    "    \n",
    "    print('Starting training with learning rate = '+ str(learning_rate))\n",
    "    for epoch in range(5):\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            inputs = inputs.float()\n",
    "            optimizer.zero_grad()\n",
    "            output = model(inputs)\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            if i % 50 == 49:\n",
    "                print('[%d, %5d] loss: %.3f' %(epoch + 1, i + 1, running_loss / 50))\n",
    "                running_loss = 0.0\n",
    "            \n",
    "\n",
    "    print('Finished Training the model')\n",
    "            \n",
    "            \n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    #model(inputs.permute(0, 3, 1, 2))\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for data in test_loader:\n",
    "            images, labels = data[0].to(device), data[1].to(device) \n",
    "            images = images.float()\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        accr = (100 * correct / total)\n",
    "            \n",
    "        print('Accuracy of the model network: %d %%' % (accr))\n",
    "        return accr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "0a1794a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training with learning rate = 0.01\n",
      "[1,    50] loss: 10.631\n",
      "[1,   100] loss: 10.711\n",
      "[1,   150] loss: 4.086\n",
      "[1,   200] loss: 6.413\n",
      "[1,   250] loss: 6.353\n",
      "[1,   300] loss: 11.117\n",
      "[1,   350] loss: 12.837\n",
      "[1,   400] loss: 9.169\n",
      "[1,   450] loss: 8.691\n",
      "[1,   500] loss: 9.556\n",
      "[1,   550] loss: 9.172\n",
      "[1,   600] loss: 14.380\n",
      "[1,   650] loss: 8.242\n",
      "[1,   700] loss: 7.042\n",
      "[1,   750] loss: 3.608\n",
      "[1,   800] loss: 12.151\n",
      "[1,   850] loss: 9.147\n",
      "[1,   900] loss: 3.614\n",
      "[1,   950] loss: 3.812\n",
      "[1,  1000] loss: 21.160\n",
      "[1,  1050] loss: 32.411\n",
      "[1,  1100] loss: 13.885\n",
      "[1,  1150] loss: 5.316\n",
      "[1,  1200] loss: 5.218\n",
      "[2,    50] loss: 7.223\n",
      "[2,   100] loss: 9.656\n",
      "[2,   150] loss: 8.551\n",
      "[2,   200] loss: 9.845\n",
      "[2,   250] loss: 12.550\n",
      "[2,   300] loss: 7.500\n",
      "[2,   350] loss: 5.452\n",
      "[2,   400] loss: 8.534\n",
      "[2,   450] loss: 3.598\n",
      "[2,   500] loss: 8.823\n",
      "[2,   550] loss: 4.528\n",
      "[2,   600] loss: 4.414\n",
      "[2,   650] loss: 11.358\n",
      "[2,   700] loss: 5.407\n",
      "[2,   750] loss: 9.885\n",
      "[2,   800] loss: 6.691\n",
      "[2,   850] loss: 7.441\n",
      "[2,   900] loss: 5.285\n",
      "[2,   950] loss: 4.616\n",
      "[2,  1000] loss: 4.830\n",
      "[2,  1050] loss: 3.169\n",
      "[2,  1100] loss: 7.387\n",
      "[2,  1150] loss: 4.174\n",
      "[2,  1200] loss: 7.151\n",
      "[3,    50] loss: 5.120\n",
      "[3,   100] loss: 17.167\n",
      "[3,   150] loss: 6.018\n",
      "[3,   200] loss: 23.529\n",
      "[3,   250] loss: 34.771\n",
      "[3,   300] loss: 13.650\n",
      "[3,   350] loss: 7.848\n",
      "[3,   400] loss: 6.809\n",
      "[3,   450] loss: 4.383\n",
      "[3,   500] loss: 3.984\n",
      "[3,   550] loss: 8.983\n",
      "[3,   600] loss: 2.977\n",
      "[3,   650] loss: 9.580\n",
      "[3,   700] loss: 7.740\n",
      "[3,   750] loss: 9.448\n",
      "[3,   800] loss: 13.809\n",
      "[3,   850] loss: 9.401\n",
      "[3,   900] loss: 11.793\n",
      "[3,   950] loss: 6.510\n",
      "[3,  1000] loss: 7.633\n",
      "[3,  1050] loss: 4.132\n",
      "[3,  1100] loss: 3.862\n",
      "[3,  1150] loss: 6.439\n",
      "[3,  1200] loss: 15.567\n",
      "[4,    50] loss: 10.436\n",
      "[4,   100] loss: 3.730\n",
      "[4,   150] loss: 3.426\n",
      "[4,   200] loss: 9.490\n",
      "[4,   250] loss: 11.122\n",
      "[4,   300] loss: 11.549\n",
      "[4,   350] loss: 9.457\n",
      "[4,   400] loss: 23.292\n",
      "[4,   450] loss: 1.454\n",
      "[4,   500] loss: 4.168\n",
      "[4,   550] loss: 10.538\n",
      "[4,   600] loss: 4.352\n",
      "[4,   650] loss: 4.491\n",
      "[4,   700] loss: 5.904\n",
      "[4,   750] loss: 7.612\n",
      "[4,   800] loss: 10.564\n",
      "[4,   850] loss: 21.246\n",
      "[4,   900] loss: 5.643\n",
      "[4,   950] loss: 6.367\n",
      "[4,  1000] loss: 7.575\n",
      "[4,  1050] loss: 4.999\n",
      "[4,  1100] loss: 3.342\n",
      "[4,  1150] loss: 13.597\n",
      "[4,  1200] loss: 7.612\n",
      "[5,    50] loss: 27.033\n",
      "[5,   100] loss: 30.565\n",
      "[5,   150] loss: 6.677\n",
      "[5,   200] loss: 5.333\n",
      "[5,   250] loss: 5.655\n",
      "[5,   300] loss: 3.487\n",
      "[5,   350] loss: 3.381\n",
      "[5,   400] loss: 9.150\n",
      "[5,   450] loss: 7.008\n",
      "[5,   500] loss: 9.457\n",
      "[5,   550] loss: 10.591\n",
      "[5,   600] loss: 11.028\n",
      "[5,   650] loss: 11.614\n",
      "[5,   700] loss: 5.227\n",
      "[5,   750] loss: 6.088\n",
      "[5,   800] loss: 4.460\n",
      "[5,   850] loss: 17.758\n",
      "[5,   900] loss: 5.431\n",
      "[5,   950] loss: 5.817\n",
      "[5,  1000] loss: 6.054\n",
      "[5,  1050] loss: 10.618\n",
      "[5,  1100] loss: 21.073\n",
      "[5,  1150] loss: 14.176\n",
      "[5,  1200] loss: 7.530\n",
      "Finished Training the model\n",
      "Accuracy of the model network: 33 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "33.333333333333336"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "train_model_and_test(densenet, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "831633d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4b17a074",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(44944, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "54eba946",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0f5b3417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        if (labels==1)|(labels==0):\n",
    "\n",
    "        # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 2000))\n",
    "                running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "89a24c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 53 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in test_dataloader:\n",
    "        \n",
    "        images, labels = data\n",
    "        if (labels==1)|(labels==0):\n",
    "        # calculate outputs by running images through the network\n",
    "            outputs = net(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34f1bf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
